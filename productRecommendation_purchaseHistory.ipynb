{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'product': 'Tang  Lemon 500 Gm(165*24)', 'similarity_score': 0.997, 'recommended_qty': 480.0, 'avg_price': 104.56, 'purchase_frequency': 9}, {'product': 'Tang Mango 500 Gm(165*24)', 'similarity_score': 0.997, 'recommended_qty': 360.0, 'avg_price': 104.59, 'purchase_frequency': 10}, {'product': 'Lifebuoy Silver Shield125Gm PO4(150*30)', 'similarity_score': 0.396, 'recommended_qty': 300.0, 'avg_price': 104.9, 'purchase_frequency': 26}, {'product': 'DETTOL SOAP ORG 100gx4(154*42)', 'similarity_score': 0.392, 'recommended_qty': 420.0, 'avg_price': 101.84, 'purchase_frequency': 42}, {'product': 'DETTOL SOAP ORG 100gx4 (154*42)', 'similarity_score': 0.392, 'recommended_qty': 420.0, 'avg_price': 101.82, 'purchase_frequency': 59}]\n",
      "\n",
      "Recommended Product: Tang  Lemon 500 Gm(165*24)\n",
      "Similarity Score: 0.997\n",
      "Recommended Quantity: 480.0\n",
      "Average Price: ₹104.56\n",
      "Purchase Frequency: 9 times\n",
      "\n",
      "Recommended Product: Tang Mango 500 Gm(165*24)\n",
      "Similarity Score: 0.997\n",
      "Recommended Quantity: 360.0\n",
      "Average Price: ₹104.59\n",
      "Purchase Frequency: 10 times\n",
      "\n",
      "Recommended Product: Lifebuoy Silver Shield125Gm PO4(150*30)\n",
      "Similarity Score: 0.396\n",
      "Recommended Quantity: 300.0\n",
      "Average Price: ₹104.9\n",
      "Purchase Frequency: 26 times\n",
      "\n",
      "Recommended Product: DETTOL SOAP ORG 100gx4(154*42)\n",
      "Similarity Score: 0.392\n",
      "Recommended Quantity: 420.0\n",
      "Average Price: ₹101.84\n",
      "Purchase Frequency: 42 times\n",
      "\n",
      "Recommended Product: DETTOL SOAP ORG 100gx4 (154*42)\n",
      "Similarity Score: 0.392\n",
      "Recommended Quantity: 420.0\n",
      "Average Price: ₹101.82\n",
      "Purchase Frequency: 59 times\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "class ProductRecommender:\n",
    "    def __init__(self, sales_data_path: str):\n",
    "        \"\"\"Initialize the recommender system with sales data\"\"\"\n",
    "        self.sales_df = pd.read_csv(sales_data_path)\n",
    "        self.cart_matrix = self._create_cart_matrix()\n",
    "        self.price_ranges = self._calculate_price_ranges()\n",
    "        self.item_purchase_patterns = self._analyze_purchase_patterns()\n",
    "        \n",
    "    def _create_cart_matrix(self) -> Dict[str, Dict[str, float]]:\n",
    "        \"\"\"Create a matrix of cart co-occurrences with purchase frequency weights\"\"\"\n",
    "        cart_matrix = defaultdict(lambda: defaultdict(float))\n",
    "        \n",
    "        # Group by VchNo to get items purchased together\n",
    "        for vch_no, group in self.sales_df.groupby('VchNo'):\n",
    "            items = group['Product Name'].unique()\n",
    "            \n",
    "            # Calculate normalized quantities for weighting\n",
    "            qty_dict = dict(zip(group['Product Name'], group['Qty']))\n",
    "            \n",
    "            # Update co-occurrence matrix\n",
    "            for item1 in items:\n",
    "                for item2 in items:\n",
    "                    if item1 != item2:\n",
    "                        # Weight by quantity purchased together\n",
    "                        weight = np.log1p(min(qty_dict[item1], qty_dict[item2]))\n",
    "                        cart_matrix[item1][item2] += weight\n",
    "        \n",
    "        return cart_matrix\n",
    "    \n",
    "    def _calculate_price_ranges(self) -> Dict[str, Tuple[float, float]]:\n",
    "        \"\"\"Calculate acceptable price ranges for each product\"\"\"\n",
    "        price_ranges = {}\n",
    "        \n",
    "        for product in self.sales_df['Product Name'].unique():\n",
    "            prices = self.sales_df[self.sales_df['Product Name'] == product]['Price']\n",
    "            mean_price = prices.mean()\n",
    "            std_price = prices.std()\n",
    "            \n",
    "            # Define price range as mean ± 1.5 standard deviations\n",
    "            price_ranges[product] = (\n",
    "                mean_price - 1.5 * std_price if not pd.isna(std_price) else mean_price * 0.5,\n",
    "                mean_price + 1.5 * std_price if not pd.isna(std_price) else mean_price * 1.5\n",
    "            )\n",
    "        \n",
    "        return price_ranges\n",
    "    \n",
    "    def _analyze_purchase_patterns(self) -> Dict[str, Dict[str, float]]:\n",
    "        \"\"\"Analyze typical purchase patterns for each product\"\"\"\n",
    "        patterns = {}\n",
    "        \n",
    "        for product in self.sales_df['Product Name'].unique():\n",
    "            product_data = self.sales_df[self.sales_df['Product Name'] == product]\n",
    "            \n",
    "            patterns[product] = {\n",
    "                'avg_qty': product_data['Qty'].mean(),\n",
    "                'median_qty': product_data['Qty'].median(),\n",
    "                'price': product_data['Price'].mean(),\n",
    "                'purchase_frequency': len(product_data)\n",
    "            }\n",
    "            \n",
    "        return patterns\n",
    "    \n",
    "    def _calculate_item_similarity(self, item1: str, item2: str) -> float:\n",
    "        \"\"\"Calculate similarity between two items based on co-purchase patterns and price\"\"\"\n",
    "        if item1 not in self.item_purchase_patterns or item2 not in self.item_purchase_patterns:\n",
    "            return 0.0\n",
    "        \n",
    "        # Price similarity (normalized)\n",
    "        price1 = self.item_purchase_patterns[item1]['price']\n",
    "        price2 = self.item_purchase_patterns[item2]['price']\n",
    "        price_diff = abs(price1 - price2) / max(price1, price2)\n",
    "        price_similarity = 1 - min(price_diff, 1)\n",
    "        \n",
    "        # Co-purchase similarity\n",
    "        copurchase_weight = self.cart_matrix[item1][item2] + self.cart_matrix[item2][item1]\n",
    "        \n",
    "        # Combine similarities with weights\n",
    "        total_similarity = (price_similarity * 0.4 + \n",
    "                          min(copurchase_weight / 10, 1) * 0.6)\n",
    "        \n",
    "        return total_similarity\n",
    "    \n",
    "    def get_recommendations(self, \n",
    "                          product: str, \n",
    "                          qty: float, \n",
    "                          price: float, \n",
    "                          n_recommendations: int = 5) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Get product recommendations based on input product, quantity, and price\n",
    "        \n",
    "        Args:\n",
    "            product: Name of the product\n",
    "            qty: Quantity purchased\n",
    "            price: Price per unit\n",
    "            n_recommendations: Number of recommendations to return\n",
    "            \n",
    "        Returns:\n",
    "            List of recommended products with their details\n",
    "        \"\"\"\n",
    "        if product not in self.item_purchase_patterns:\n",
    "            return []\n",
    "        \n",
    "        # Get all products within similar price range\n",
    "        target_price_range = self.price_ranges[product]\n",
    "        candidate_products = [\n",
    "            p for p in self.item_purchase_patterns.keys()\n",
    "            if p != product and\n",
    "            target_price_range[0] <= self.item_purchase_patterns[p]['price'] <= target_price_range[1]\n",
    "        ]\n",
    "        \n",
    "        # Calculate similarities for all candidate products\n",
    "        similarities = [\n",
    "            (p, self._calculate_item_similarity(product, p))\n",
    "            for p in candidate_products\n",
    "        ]\n",
    "        \n",
    "        # Sort by similarity and get top recommendations\n",
    "        recommendations = []\n",
    "        for prod, similarity in sorted(similarities, key=lambda x: x[1], reverse=True)[:n_recommendations]:\n",
    "            pattern = self.item_purchase_patterns[prod]\n",
    "            \n",
    "            recommendations.append({\n",
    "                'product': prod,\n",
    "                'similarity_score': round(similarity, 3),\n",
    "                'recommended_qty': round(pattern['median_qty'], 2),\n",
    "                'avg_price': round(pattern['price'], 2),\n",
    "                'purchase_frequency': pattern['purchase_frequency']\n",
    "            })\n",
    "        \n",
    "        return recommendations\n",
    "\n",
    "    def _validate_input(self, product: str, qty: float, price: float) -> bool:\n",
    "        \"\"\"Validate input parameters\"\"\"\n",
    "        if product not in self.item_purchase_patterns:\n",
    "            return False\n",
    "        \n",
    "        pattern = self.item_purchase_patterns[product]\n",
    "        price_range = self.price_ranges[product]\n",
    "        \n",
    "        if price < price_range[0] * 0.5 or price > price_range[1] * 1.5:\n",
    "            return False\n",
    "        \n",
    "        if qty < 0 or qty > pattern['avg_qty'] * 10:\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "\n",
    "# Example usage\n",
    "recommender = ProductRecommender(\"SALE DATA.csv\")\n",
    "\n",
    "# Get recommendations for a product\n",
    "recommendations = recommender.get_recommendations(\n",
    "    product=\"Tang  Orange 500 Gm (165*24)\",\n",
    "    qty=140,\n",
    "    price=105\n",
    ")\n",
    "print(recommendations)\n",
    "\n",
    "# Print recommendations\n",
    "for rec in recommendations:\n",
    "    print(f\"\\nRecommended Product: {rec['product']}\")\n",
    "    print(f\"Similarity Score: {rec['similarity_score']}\")\n",
    "    print(f\"Recommended Quantity: {rec['recommended_qty']}\")\n",
    "    print(f\"Average Price: ₹{rec['avg_price']}\")\n",
    "    print(f\"Purchase Frequency: {rec['purchase_frequency']} times\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the abovecode produces good output from similar cart but may have some repeated items.\n",
    "# it also does not consider the case where the cart is empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommendations:\n",
      "\n",
      "Product: Dove BathingSoap 100gm+20gm(65*60)\n",
      "Similarity Score: 0.664\n",
      "Confidence Score: 0.597\n",
      "Recommendation Type: collaborative\n",
      "Similarity Components: {'price_similarity': 0.785, 'pattern_similarity': 0.999, 'copurchase_strength': 0.558, 'customer_overlap': 0.083}\n",
      "Recommended Quantity: 600.0\n",
      "Average Price: ₹42.72\n",
      "Purchase Frequency: 9\n",
      "\n",
      "Product: Odomos Cream Natural 100gm(115*36)\n",
      "Similarity Score: 0.632\n",
      "Confidence Score: 0.569\n",
      "Recommendation Type: collaborative\n",
      "Similarity Components: {'price_similarity': 0.542, 'pattern_similarity': 0.977, 'copurchase_strength': 0.683, 'customer_overlap': 0.2}\n",
      "Recommended Quantity: 1350.0\n",
      "Average Price: ₹61.89\n",
      "Purchase Frequency: 2\n",
      "\n",
      "Product: Pears Pure & Gentle Soap 120g(54*72)\n",
      "Similarity Score: 0.611\n",
      "Confidence Score: 0.55\n",
      "Recommendation Type: collaborative\n",
      "Similarity Components: {'price_similarity': 0.927, 'pattern_similarity': 0.977, 'copurchase_strength': 0.0, 'customer_overlap': 0.2}\n",
      "Recommended Quantity: 36.0\n",
      "Average Price: ₹36.15\n",
      "Purchase Frequency: 1\n",
      "\n",
      "Product: Odomos 50 GM Cream Vitamin-E(58*72)\n",
      "Similarity Score: 0.604\n",
      "Confidence Score: 0.544\n",
      "Recommendation Type: collaborative\n",
      "Similarity Components: {'price_similarity': 0.946, 'pattern_similarity': 0.569, 'copurchase_strength': 0.673, 'customer_overlap': 0.075}\n",
      "Recommended Quantity: 720.0\n",
      "Average Price: ₹31.7\n",
      "Purchase Frequency: 76\n",
      "\n",
      "Product: Everyouth  Walnut Scrub 25G(59*384)\n",
      "Similarity Score: 0.604\n",
      "Confidence Score: 0.544\n",
      "Recommendation Type: collaborative\n",
      "Similarity Components: {'price_similarity': 0.982, 'pattern_similarity': 0.984, 'copurchase_strength': 0.0, 'customer_overlap': 0.071}\n",
      "Recommended Quantity: 768.0\n",
      "Average Price: ₹34.15\n",
      "Purchase Frequency: 12\n",
      "\n",
      "Evaluation Metrics:\n",
      "silhouette_score: -0.654\n",
      "average_similarity: 0.623\n",
      "average_confidence: 0.561\n",
      "price_cohesion: 0.745\n",
      "diversity_score: 0.2\n",
      "collaborative_ratio: 1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics import silhouette_score\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class ProductRecommender:\n",
    "    def __init__(self, sales_data_path: str):\n",
    "        \"\"\"Initialize the recommender system with sales data\"\"\"\n",
    "        self.sales_df = pd.read_csv(sales_data_path)\n",
    "        self.cart_matrix = self._create_cart_matrix()\n",
    "        self.price_ranges = self._calculate_price_ranges()\n",
    "        self.item_purchase_patterns = self._analyze_purchase_patterns()\n",
    "        self.product_features = self._create_product_features()\n",
    "        \n",
    "    def _create_product_features(self) -> pd.DataFrame:\n",
    "        \"\"\"Create feature matrix for products\"\"\"\n",
    "        features = []\n",
    "        \n",
    "        for product in self.sales_df['Product Name'].unique():\n",
    "            product_data = self.sales_df[self.sales_df['Product Name'] == product]\n",
    "            \n",
    "            # Calculate features\n",
    "            avg_qty = product_data['Qty'].mean()\n",
    "            price = product_data['Price'].mean()\n",
    "            purchase_freq = len(product_data)\n",
    "            unique_customers = product_data['Party'].nunique()\n",
    "            \n",
    "            # Create feature vector\n",
    "            features.append({\n",
    "                'Product Name': product,\n",
    "                'avg_qty': avg_qty,\n",
    "                'price': price,\n",
    "                'purchase_freq': purchase_freq,\n",
    "                'unique_customers': unique_customers,\n",
    "                'price_per_qty': price / avg_qty if avg_qty > 0 else price\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(features).set_index('Product Name')\n",
    "    \n",
    "    def _create_cart_matrix(self) -> Dict[str, Dict[str, float]]:\n",
    "        \"\"\"Create a matrix of cart co-occurrences with purchase frequency weights\"\"\"\n",
    "        cart_matrix = defaultdict(lambda: defaultdict(float))\n",
    "        \n",
    "        # Group by VchNo to get items purchased together\n",
    "        for vch_no, group in self.sales_df.groupby('VchNo'):\n",
    "            items = group['Product Name'].unique()\n",
    "            qty_dict = dict(zip(group['Product Name'], group['Qty']))\n",
    "            \n",
    "            for item1 in items:\n",
    "                for item2 in items:\n",
    "                    if item1 != item2:\n",
    "                        # Enhanced weighting system\n",
    "                        qty_weight = np.log1p(min(qty_dict[item1], qty_dict[item2]))\n",
    "                        price_similarity = 1 - abs(\n",
    "                            group[group['Product Name'] == item1]['Price'].iloc[0] -\n",
    "                            group[group['Product Name'] == item2]['Price'].iloc[0]\n",
    "                        ) / max(group['Price'])\n",
    "                        \n",
    "                        cart_matrix[item1][item2] += qty_weight * price_similarity\n",
    "        \n",
    "        return cart_matrix\n",
    "    \n",
    "    def _calculate_price_ranges(self) -> Dict[str, Tuple[float, float]]:\n",
    "        \"\"\"Calculate dynamic price ranges for each product\"\"\"\n",
    "        price_ranges = {}\n",
    "        \n",
    "        for product in self.sales_df['Product Name'].unique():\n",
    "            prices = self.sales_df[self.sales_df['Product Name'] == product]['Price']\n",
    "            mean_price = prices.mean()\n",
    "            std_price = prices.std()\n",
    "            \n",
    "            # Dynamic range based on price volatility\n",
    "            multiplier = 1.5 if std_price/mean_price < 0.2 else 2.0\n",
    "            \n",
    "            price_ranges[product] = (\n",
    "                mean_price - multiplier * std_price if not pd.isna(std_price) else mean_price * 0.5,\n",
    "                mean_price + multiplier * std_price if not pd.isna(std_price) else mean_price * 1.5\n",
    "            )\n",
    "        \n",
    "        return price_ranges\n",
    "    \n",
    "    def _analyze_purchase_patterns(self) -> Dict[str, Dict[str, float]]:\n",
    "        \"\"\"Analyze comprehensive purchase patterns for each product\"\"\"\n",
    "        patterns = {}\n",
    "        \n",
    "        for product in self.sales_df['Product Name'].unique():\n",
    "            product_data = self.sales_df[self.sales_df['Product Name'] == product]\n",
    "            \n",
    "            patterns[product] = {\n",
    "                'avg_qty': product_data['Qty'].mean(),\n",
    "                'median_qty': product_data['Qty'].median(),\n",
    "                'price': product_data['Price'].mean(),\n",
    "                'purchase_frequency': len(product_data),\n",
    "                'unique_customers': product_data['Party'].nunique(),\n",
    "                'avg_cart_size': product_data.groupby('VchNo').size().mean()\n",
    "            }\n",
    "            \n",
    "        return patterns\n",
    "    \n",
    "    def _calculate_item_similarity(self, item1: str, item2: str) -> Tuple[float, Dict[str, float]]:\n",
    "        \"\"\"Calculate detailed similarity metrics between two items\"\"\"\n",
    "        if item1 not in self.item_purchase_patterns or item2 not in self.item_purchase_patterns:\n",
    "            return 0.0, {}\n",
    "        \n",
    "        # Price similarity\n",
    "        price1 = self.item_purchase_patterns[item1]['price']\n",
    "        price2 = self.item_purchase_patterns[item2]['price']\n",
    "        price_diff = abs(price1 - price2) / max(price1, price2)\n",
    "        price_similarity = 1 - min(price_diff, 1)\n",
    "        \n",
    "        # Purchase pattern similarity\n",
    "        pattern1 = self.product_features.loc[item1]\n",
    "        pattern2 = self.product_features.loc[item2]\n",
    "        pattern_similarity = 1 - cosine(pattern1[1:], pattern2[1:])\n",
    "        \n",
    "        # Co-purchase strength\n",
    "        copurchase_strength = (self.cart_matrix[item1][item2] + \n",
    "                             self.cart_matrix[item2][item1]) / 2\n",
    "        \n",
    "        # Customer overlap\n",
    "        customers1 = set(self.sales_df[self.sales_df['Product Name'] == item1]['Party'])\n",
    "        customers2 = set(self.sales_df[self.sales_df['Product Name'] == item2]['Party'])\n",
    "        customer_overlap = len(customers1.intersection(customers2)) / len(customers1.union(customers2))\n",
    "        \n",
    "        # Combine similarities with weights\n",
    "        similarity_components = {\n",
    "            'price_similarity': price_similarity,\n",
    "            'pattern_similarity': pattern_similarity,\n",
    "            'copurchase_strength': min(copurchase_strength / 10, 1),\n",
    "            'customer_overlap': customer_overlap\n",
    "        }\n",
    "        \n",
    "        total_similarity = (\n",
    "            price_similarity * 0.3 +\n",
    "            pattern_similarity * 0.3 +\n",
    "            min(copurchase_strength / 10, 1) * 0.2 +\n",
    "            customer_overlap * 0.2\n",
    "        )\n",
    "        \n",
    "        return total_similarity, similarity_components\n",
    "    \n",
    "    def _get_fallback_recommendations(self, \n",
    "                                    target_price: float, \n",
    "                                    excluded_products: List[str], \n",
    "                                    n_recommendations: int) -> List[Dict]:\n",
    "        \"\"\"Get recommendations based on price similarity when no direct recommendations available\"\"\"\n",
    "        price_diffs = []\n",
    "        \n",
    "        for product in self.item_purchase_patterns.keys():\n",
    "            if product not in excluded_products:\n",
    "                price = self.item_purchase_patterns[product]['price']\n",
    "                price_diff = abs(price - target_price) / max(price, target_price)\n",
    "                pattern = self.item_purchase_patterns[product]\n",
    "                \n",
    "                price_diffs.append({\n",
    "                    'product': product,\n",
    "                    'price_diff': price_diff,\n",
    "                    'pattern': pattern\n",
    "                })\n",
    "        \n",
    "        # Sort by price difference and get top matches\n",
    "        price_diffs.sort(key=lambda x: x['price_diff'])\n",
    "        recommendations = []\n",
    "        \n",
    "        for item in price_diffs[:n_recommendations]:\n",
    "            pattern = item['pattern']\n",
    "            recommendations.append({\n",
    "                'product': item['product'],\n",
    "                'similarity_score': 1 - item['price_diff'],  # Convert difference to similarity\n",
    "                'recommended_qty': pattern['median_qty'],\n",
    "                'avg_price': pattern['price'],\n",
    "                'purchase_frequency': pattern['purchase_frequency'],\n",
    "                'recommendation_type': 'price_based_fallback',\n",
    "                'confidence_score': (1 - item['price_diff']) * 0.7  # Lower confidence for fallback\n",
    "            })\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    def get_recommendations(self, \n",
    "                          product: str, \n",
    "                          qty: float, \n",
    "                          price: float, \n",
    "                          n_recommendations: int = 5) -> Tuple[List[Dict], Dict]:\n",
    "        \"\"\"\n",
    "        Get product recommendations with detailed evaluation metrics\n",
    "        \n",
    "        Returns:\n",
    "            Tuple of (recommendations list, evaluation metrics)\n",
    "        \"\"\"\n",
    "        if not self._validate_input(product, qty, price):\n",
    "            return [], {'error': 'Invalid input parameters'}\n",
    "        \n",
    "        # Get initial recommendations based on co-purchase and similarity\n",
    "        candidate_products = set(self.item_purchase_patterns.keys()) - {product}\n",
    "        similarities = []\n",
    "        \n",
    "        for candidate in candidate_products:\n",
    "            similarity, components = self._calculate_item_similarity(product, candidate)\n",
    "            if similarity > 0:\n",
    "                similarities.append((candidate, similarity, components))\n",
    "        \n",
    "        # Sort by similarity and get top recommendations\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        recommendations = []\n",
    "        used_products = set()\n",
    "        \n",
    "        # Process top similar products\n",
    "        for prod, similarity, components in similarities[:n_recommendations]:\n",
    "            if prod not in used_products:\n",
    "                pattern = self.item_purchase_patterns[prod]\n",
    "                \n",
    "                recommendation = {\n",
    "                    'product': prod,\n",
    "                    'similarity_score': round(similarity, 3),\n",
    "                    'similarity_components': {k: round(v, 3) for k, v in components.items()},\n",
    "                    'recommended_qty': round(pattern['median_qty'], 2),\n",
    "                    'avg_price': round(pattern['price'], 2),\n",
    "                    'purchase_frequency': pattern['purchase_frequency'],\n",
    "                    'recommendation_type': 'collaborative',\n",
    "                    'confidence_score': round(similarity * 0.9, 3)  # High confidence for collaborative\n",
    "                }\n",
    "                \n",
    "                recommendations.append(recommendation)\n",
    "                used_products.add(prod)\n",
    "        \n",
    "        # If we need more recommendations, add fallback recommendations\n",
    "        if len(recommendations) < n_recommendations:\n",
    "            fallback_count = n_recommendations - len(recommendations)\n",
    "            fallback_recs = self._get_fallback_recommendations(\n",
    "                price, \n",
    "                used_products.union({product}), \n",
    "                fallback_count\n",
    "            )\n",
    "            recommendations.extend(fallback_recs)\n",
    "        \n",
    "        # Calculate evaluation metrics\n",
    "        evaluation_metrics = self._calculate_evaluation_metrics(product, recommendations)\n",
    "        \n",
    "        return recommendations, evaluation_metrics\n",
    "    \n",
    "    def _calculate_evaluation_metrics(self, \n",
    "                                   target_product: str, \n",
    "                                   recommendations: List[Dict]) -> Dict:\n",
    "        \"\"\"Calculate comprehensive evaluation metrics for recommendations\"\"\"\n",
    "        if not recommendations:\n",
    "            return {'error': 'No recommendations to evaluate'}\n",
    "        \n",
    "        # Prepare feature matrix for silhouette score\n",
    "        products = [target_product] + [r['product'] for r in recommendations]\n",
    "        features = self.product_features.loc[products].values\n",
    "        \n",
    "        # Calculate silhouette score\n",
    "        if len(products) > 2:  # Silhouette score needs at least 2 samples\n",
    "            silhouette = silhouette_score(\n",
    "                features,\n",
    "                [0] + [1] * len(recommendations),\n",
    "                metric='cosine'\n",
    "            )\n",
    "        else:\n",
    "            silhouette = None\n",
    "        \n",
    "        # Calculate other metrics\n",
    "        avg_similarity = np.mean([r['similarity_score'] for r in recommendations])\n",
    "        avg_confidence = np.mean([r['confidence_score'] for r in recommendations])\n",
    "        \n",
    "        # Calculate price cohesion\n",
    "        target_price = self.item_purchase_patterns[target_product]['price']\n",
    "        price_diffs = [abs(r['avg_price'] - target_price) / target_price \n",
    "                      for r in recommendations]\n",
    "        price_cohesion = 1 - np.mean(price_diffs)\n",
    "        \n",
    "        # Calculate recommendation diversity\n",
    "        recommendation_types = [r['recommendation_type'] for r in recommendations]\n",
    "        diversity_score = len(set(recommendation_types)) / len(recommendations)\n",
    "        \n",
    "        return {\n",
    "            'silhouette_score': round(silhouette, 3) if silhouette is not None else None,\n",
    "            'average_similarity': round(avg_similarity, 3),\n",
    "            'average_confidence': round(avg_confidence, 3),\n",
    "            'price_cohesion': round(price_cohesion, 3),\n",
    "            'diversity_score': round(diversity_score, 3),\n",
    "            'collaborative_ratio': round(\n",
    "                sum(1 for r in recommendations if r['recommendation_type'] == 'collaborative') / \n",
    "                len(recommendations),\n",
    "                3\n",
    "            )\n",
    "        }\n",
    "    \n",
    "    def _validate_input(self, product: str, qty: float, price: float) -> bool:\n",
    "        \"\"\"Validate input parameters\"\"\"\n",
    "        if product not in self.item_purchase_patterns:\n",
    "            return False\n",
    "        \n",
    "        pattern = self.item_purchase_patterns[product]\n",
    "        price_range = self.price_ranges[product]\n",
    "        \n",
    "        if price < price_range[0] * 0.5 or price > price_range[1] * 1.5:\n",
    "            return False\n",
    "        \n",
    "        if qty < 0 or qty > pattern['avg_qty'] * 10:\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "\n",
    "recommender = ProductRecommender(\"SALE DATA.csv\")\n",
    "    \n",
    "    # Get recommendations with evaluation metrics\n",
    "recommendations, evaluation = recommender.get_recommendations(\n",
    "        product=\"Odomos Cream Natural 50gm(62*72)\",\n",
    "        qty=400,\n",
    "        price=32\n",
    "    )\n",
    "    \n",
    "    # Print recommendations\n",
    "print(\"\\nRecommendations:\")\n",
    "for rec in recommendations:\n",
    "        print(f\"\\nProduct: {rec['product']}\")\n",
    "        print(f\"Similarity Score: {rec['similarity_score']}\")\n",
    "        print(f\"Confidence Score: {rec['confidence_score']}\")\n",
    "        print(f\"Recommendation Type: {rec['recommendation_type']}\")\n",
    "        print(f\"Similarity Components: {rec['similarity_components']}\")\n",
    "        print(f\"Recommended Quantity: {rec['recommended_qty']}\")\n",
    "        print(f\"Average Price: ₹{rec['avg_price']}\")\n",
    "        print(f\"Purchase Frequency: {rec['purchase_frequency']}\")\n",
    "    \n",
    "    # Print evaluation metrics\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "for metric, value in evaluation.items():\n",
    "        print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Because K means perform poorly for the cases of high Dimensionality and sparse data, we will use the Adapttive Fusion Weights with Multigraph algorithm as alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommended products:\n",
      "\n",
      "1. Lipton Green Tea Lemon- Honey(170*24)\n",
      "   Similarity Score: 0.39\n",
      "   Confidence Score: 0.39\n",
      "   Average Price: ₹112.54\n",
      "   Typical Quantity: 497\n",
      "\n",
      "2. Vaseline  Deep Moisture 400ml (435*36)\n",
      "   Similarity Score: 0.45\n",
      "   Confidence Score: 0.39\n",
      "   Average Price: ₹146.19\n",
      "   Typical Quantity: 345\n",
      "\n",
      "3. Lifebuoy Silver Shield125Gm PO5(155*30)\n",
      "   Similarity Score: 0.37\n",
      "   Confidence Score: 0.33\n",
      "   Average Price: ₹107.63\n",
      "   Typical Quantity: 696\n",
      "\n",
      "4. Horlicks Chocolate Jar -500g (249*24)\n",
      "   Similarity Score: 0.38\n",
      "   Confidence Score: 0.32\n",
      "   Average Price: ₹144.25\n",
      "   Typical Quantity: 387\n",
      "\n",
      "5. TATA TEA PRM LEAF 500GM(255*48)\n",
      "   Similarity Score: 0.36\n",
      "   Confidence Score: 0.30\n",
      "   Average Price: ₹158.52\n",
      "   Typical Quantity: 546\n"
     ]
    }
   ],
   "source": [
    "#apart from K means, trying with the method of Adaptive Weights\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from datetime import datetime\n",
    "\n",
    "class ProductRecommender:\n",
    "    def __init__(self):\n",
    "        self.purchase_history = pd.DataFrame()\n",
    "        self.customer_encoder = LabelEncoder()\n",
    "        self.product_encoder = LabelEncoder()\n",
    "        self.customer_product_matrix = None\n",
    "        self.product_similarity_matrix = None\n",
    "        self.product_mapping = {}\n",
    "\n",
    "    def parse_date(self, date_str):\n",
    "        try:\n",
    "            return pd.to_datetime(date_str, errors='coerce')\n",
    "        except:\n",
    "            return pd.NaT\n",
    "\n",
    "    def load_and_process_data(self, sales_file, customer_file):\n",
    "        # Read data\n",
    "        sales_df = pd.read_csv(sales_file, encoding='utf-8', on_bad_lines='skip')\n",
    "        customers_df = pd.read_csv(customer_file, encoding='utf-8', on_bad_lines='skip')\n",
    "        # Clean data\n",
    "        sales_df = sales_df.dropna(subset=['Product Name', 'Party', 'Qty', 'Price'])\n",
    "        self.purchase_history = sales_df[['Product Name', 'Party', 'Qty', 'Price', 'Date']].copy()\n",
    "        self.purchase_history['Date'] = self.purchase_history['Date'].apply(self.parse_date)\n",
    "        self.purchase_history['Product Name'] = self.purchase_history['Product Name'].str.strip()\n",
    "        self.purchase_history['Party'] = self.purchase_history['Party'].str.strip()\n",
    "        self.purchase_history = self.purchase_history.drop_duplicates()\n",
    "        # Encode\n",
    "        try:\n",
    "            self.purchase_history['CustomerEncoded'] = self.customer_encoder.fit_transform(\n",
    "                self.purchase_history['Party']\n",
    "            )\n",
    "            self.purchase_history['ProductEncoded'] = self.product_encoder.fit_transform(\n",
    "                self.purchase_history['Product Name']\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error during encoding: {e}\")\n",
    "            raise\n",
    "        self.product_mapping = dict(zip(\n",
    "            self.product_encoder.transform(self.product_encoder.classes_),\n",
    "            self.product_encoder.classes_\n",
    "        ))\n",
    "        # Create interaction matrix\n",
    "        self.create_interaction_matrix()\n",
    "        # Calculate similarity\n",
    "        self.calculate_product_similarity()\n",
    "\n",
    "    def create_interaction_matrix(self):\n",
    "        try:\n",
    "            interaction_df = self.purchase_history.groupby(\n",
    "                ['CustomerEncoded', 'ProductEncoded']\n",
    "            ).agg({\n",
    "                'Qty': 'sum',\n",
    "                'Price': 'mean',\n",
    "                'Date': 'max'\n",
    "            }).reset_index()\n",
    "            current_date = pd.Timestamp.now()\n",
    "            interaction_df['DaysSinceLastPurchase'] = (\n",
    "                current_date - interaction_df['Date']\n",
    "            ).dt.days\n",
    "            interaction_df['TimeWeight'] = np.exp(-0.001 * interaction_df['DaysSinceLastPurchase'])\n",
    "            interaction_df['InteractionScore'] = (\n",
    "                np.log1p(interaction_df['Qty']) *\n",
    "                interaction_df['Price'] *\n",
    "                interaction_df['TimeWeight']\n",
    "            )\n",
    "            # Pivot into matrix\n",
    "            self.customer_product_matrix = interaction_df.pivot(\n",
    "                index='CustomerEncoded',\n",
    "                columns='ProductEncoded',\n",
    "                values='InteractionScore'\n",
    "            ).fillna(0)\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating interaction matrix: {e}\")\n",
    "            self.customer_product_matrix = None\n",
    "\n",
    "    def calculate_product_similarity(self):\n",
    "        try:\n",
    "            self.product_similarity_matrix = cosine_similarity(self.customer_product_matrix.T)\n",
    "        except Exception as e:\n",
    "            print(f\"Error during similarity calculation: {e}\")\n",
    "            raise\n",
    "\n",
    "    def get_similar_products(self, current_product, n=5):\n",
    "        if current_product not in self.product_encoder.classes_:\n",
    "            return f\"No data available for '{current_product}'\"\n",
    "        product_encoded = self.product_encoder.transform([current_product])[0]\n",
    "        similarity_scores = self.product_similarity_matrix[product_encoded]\n",
    "        top_indices = similarity_scores.argsort()[::-1][1:n+1]\n",
    "        return [(self.product_mapping[idx], similarity_scores[idx]) for idx in top_indices]\n",
    "\n",
    "    def calculate_dynamic_price_range(self, price):\n",
    "        if price < 50:\n",
    "            return (0.6 * price, 1.4 * price)\n",
    "        elif price < 200:\n",
    "            return (0.7 * price, 1.3 * price)\n",
    "        else:\n",
    "            return (0.8 * price, 1.2 * price)\n",
    "\n",
    "    def calculate_confidence_score(self, similarity, n_purchases):\n",
    "        purchase_weight = min(1, np.log1p(n_purchases) / np.log1p(100))\n",
    "        return similarity * purchase_weight\n",
    "\n",
    "    def recommend_products(self, current_product, price, quantity, n_recommendations=5):\n",
    "        try:\n",
    "            similar_products = self.get_similar_products(current_product, n_recommendations*5)\n",
    "            if isinstance(similar_products, str):\n",
    "                return similar_products\n",
    "            \n",
    "            price_range = self.calculate_dynamic_price_range(price)\n",
    "            filtered_recommendations = []\n",
    "            seen_patterns = set()  # Track similar product patterns\n",
    "            \n",
    "            # Helper function to check if product is similar to existing ones\n",
    "            def is_similar_to_existing(prod_name):\n",
    "                prod_parts = set(prod_name.lower().split())\n",
    "                # Check for substantial overlap with existing products\n",
    "                for pattern in seen_patterns:\n",
    "                    pattern_parts = set(pattern.split())\n",
    "                    if len(prod_parts.intersection(pattern_parts)) >= 2:  # If 2 or more words match\n",
    "                        return True\n",
    "                return False\n",
    "            \n",
    "            for prod, similarity in similar_products:\n",
    "                # Skip if product is too similar to ones we've already selected\n",
    "                if is_similar_to_existing(prod):\n",
    "                    continue\n",
    "                    \n",
    "                prod_data = self.purchase_history[self.purchase_history['Product Name'] == prod]\n",
    "                if not prod_data.empty:\n",
    "                    avg_price = prod_data['Price'].mean()\n",
    "                    avg_quantity = prod_data['Qty'].mean()\n",
    "                    if price_range[0] <= avg_price <= price_range[1]:\n",
    "                        confidence = self.calculate_confidence_score(\n",
    "                            similarity, prod_data.shape[0]\n",
    "                        )\n",
    "                        filtered_recommendations.append({\n",
    "                            'product': prod,\n",
    "                            'similarity_score': similarity,\n",
    "                            'avg_price': avg_price,\n",
    "                            'typical_quantity': avg_quantity,\n",
    "                            'confidence_score': confidence\n",
    "                        })\n",
    "                        # Add product pattern to seen patterns\n",
    "                        seen_patterns.add(' '.join(prod.lower().split()))\n",
    "                        \n",
    "                        if len(filtered_recommendations) >= n_recommendations:\n",
    "                            break\n",
    "                            \n",
    "            # If we don't have enough recommendations, try to find products in similar price range\n",
    "            if len(filtered_recommendations) < n_recommendations:\n",
    "                price_similar_products = self.purchase_history[\n",
    "                    (self.purchase_history['Price'] >= price_range[0]) & \n",
    "                    (self.purchase_history['Price'] <= price_range[1]) &\n",
    "                    (~self.purchase_history['Product Name'].isin([r['product'] for r in filtered_recommendations]))\n",
    "                ]['Product Name'].unique()\n",
    "                \n",
    "                for prod in price_similar_products:\n",
    "                    if is_similar_to_existing(prod):\n",
    "                        continue\n",
    "                        \n",
    "                    prod_data = self.purchase_history[self.purchase_history['Product Name'] == prod]\n",
    "                    if not prod_data.empty:\n",
    "                        avg_price = prod_data['Price'].mean()\n",
    "                        similarity = 0.3  # Base similarity for price-based recommendations\n",
    "                        confidence = self.calculate_confidence_score(\n",
    "                            similarity, prod_data.shape[0]\n",
    "                        )\n",
    "                        filtered_recommendations.append({\n",
    "                            'product': prod,\n",
    "                            'similarity_score': similarity,\n",
    "                            'avg_price': avg_price,\n",
    "                            'typical_quantity': prod_data['Qty'].mean(),\n",
    "                            'confidence_score': confidence\n",
    "                        })\n",
    "                        seen_patterns.add(' '.join(prod.lower().split()))\n",
    "                        \n",
    "                    if len(filtered_recommendations) >= n_recommendations:\n",
    "                        break\n",
    "                        \n",
    "            filtered_recommendations.sort(key=lambda x: x['confidence_score'], reverse=True)\n",
    "            return filtered_recommendations[:n_recommendations]\n",
    "        except Exception as e:\n",
    "            print(f\"Error during recommendation generation: {e}\")\n",
    "            return []\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        recommender = ProductRecommender()\n",
    "        recommender.load_and_process_data('SALE DATA.csv', 'CUSTOMER DATABASE.csv')\n",
    "        sample_product = \"Dabur Amla HairOil450ml(225*32)Offer\"\n",
    "        sample_price = 127\n",
    "        sample_quantity = 5000\n",
    "        recommendations = recommender.recommend_products(sample_product, sample_price, sample_quantity)\n",
    "        return recommendations\n",
    "    except Exception as e:\n",
    "        print(f\"Error in main execution: {e}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    recs = main()\n",
    "    if recs:\n",
    "        print(\"\\nRecommended products:\")\n",
    "        for i, rec in enumerate(recs, 1):\n",
    "            print(f\"\\n{i}. {rec['product']}\")\n",
    "            print(f\"   Similarity Score: {rec['similarity_score']:.2f}\")\n",
    "            print(f\"   Confidence Score: {rec['confidence_score']:.2f}\")\n",
    "            print(f\"   Average Price: ₹{rec['avg_price']:.2f}\")\n",
    "            print(f\"   Typical Quantity: {rec['typical_quantity']:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
